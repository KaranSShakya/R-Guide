---
title: "Applied Econometrics"
site: workflowr::wflow_site
output:  
  html_document
---

```{r eval=T, echo=F, warning=F, message=F}
# Packages
library(knitr)
library(tidyverse)
library(readxl)
library(broom)
library(stargazer)
library(jtools)

library(GGally)
library(gridExtra)
library(AER)
```

```{r eval=T, echo=F}
consumption <- read_excel("data/data_8731.xlsx", 
                        sheet = "consumption")
classical <- read_excel("data/data_8731.xlsx", 
                        sheet = "classical")
classical <- read_excel("data/data_8731.xlsx", 
                        sheet = "classical")
earnings <- read_excel("data/data_8731.xlsx", 
                       sheet = "earnings")
```

# Lagged Regression 
Dataset is:
```{r eval=T, echo=F}
head(consumption, 2)
```
$c_t$ is log of consumption, $y_t$ is log of income. Their first differences are $\Delta c_t = c_t - c_{t-1}$ and $\Delta y_t = y_t - y_{t-1}$.

The **model** for the period 1953:1 to 1996:4,
$$
\Delta c_t = \beta_1 + \beta_2 \Delta y_t + \beta_3 \Delta y_{t-1} + \beta_4 \Delta y_{t-2} + \beta_5 \Delta y_{t-3} + \beta_6 \Delta y_{t-4}
$$
## Estimation
Let $\gamma = \sum_{l=2}^{6} \beta_l$. Calculate $\hat{\gamma}$ and its SE.

```{r eval=T, echo=T}
consumption1 <- consumption %>% 
  mutate(ct = log(Consumption), yt=log(Income),
         del_ct = ct-lag(ct),
         del_yt = yt-lag(yt),
         yt1 = lag(yt, 1),
         yt2 = lag(yt, 2),
         yt3 = lag(yt, 3),
         yt4 = lag(yt, 4),
         del_yt1 = yt1-lag(yt1),
         del_yt2 = yt2-lag(yt2),
         del_yt3 = yt3-lag(yt3),
         del_yt4 = yt4-lag(yt4),
         ct1 = lag(ct, 1)) #adding new variables 

cons1 <- consumption1 %>% 
  filter(Year >= 1953 & Year <= 1996)

cons1.model <- lm(del_ct ~ del_yt+del_yt1+del_yt2+del_yt3+del_yt4, data=cons1)
summ(cons1.model, digits = 4)
```

```{r eval=T, echo=T}
gamma_h <- cons1.model$coefficients[2]+cons1.model$coefficients[3]+
  cons1.model$coefficients[4]+cons1.model$coefficients[5]+
  cons1.model$coefficients[6]
kable(gamma_h, row.names = F, align = "l")
```

***

# Hypothesis Tests
The dataset is as follows:
```{r eval=T, echo=F}
head(classical, 5)
```
Classical linear regression model,
$$
\begin{align}
y = \beta_1 + \beta_2 x_2 + \beta_3 x_3 + u, && u \sim N (0, \sigma^2 I) 
\end{align}
$$
```{r eval=T, echo=T}
model.class <- lm(Dep~X_2+X_3, data = classical)
summ(model.class, digits = 4)
```
**test $\beta_3 = 0$**
```{r eval=T, echo=T}
linearHypothesis(model.class, "X_3 = 0")
```

Or we could have simply looked at the **t-value** provided at the `summ` table. The **p-values** are the same for both.

```{r eval=T, echo=F}
remove(classical, model.class,X_3)
```

***

# Dummy Variables
Dummy variable dataset, where Group 1, Group 2, and Group 3 are dummy variables.
```{r eval=T, echo=F}
head(earnings, 3)
```

Regress y on all 3 dummy variables. Important to remove the intercept term. And construct a **0.95** CI of Group3:
```{r eval=T, echo=T}
model.dum <- lm(Earnings~-1+Group1+Group2+Group3, data=earnings)
summ(model.dum, confint = T, ci.width = 0.95, digits = 2)
```

Regress y on Group3 only:
```{r eval=T, echo=T}
model.dum3 <- lm(Earnings~-1+Group3, data=earnings)
summ(model.dum3, digits = 2, confint = T, ci.width = 0.95, robust = "HC1")
```

```{r eval=T, echo=F}
remove(earnings, model.dum, model.dum3)
```

# Log - Elasticities

# Cobb-Douglas Function